dataloader:
  n_jobs: 6                                             # Subprocess used for torch Dataloader
  batch_size: 6                                         # training batch size
  dev_batch_size: 12                                    # used for dev/test splits
  max_timestep: 0                                       # Max length for audio feature (0 for no restriction)

  data_path: 'data/libri_fmllr_cmvn'                    # Source data path, 'data/libri_fmllr_cmvn', or 'data/libri_mfcc_cmvn', or 'data/libri_mel160_subword5000' for different preprocessing features
  phone_path: 'data/cpc_phone'                          # phone boundary label data path for the phone classification task. set to 'data/libri_phone' or 'data/cpc_phone'
  libri_root: '/media/andi611/1TBSSD/LibriSpeech/'      # only used when extract features on-the-fly
  train_set: ['train-clean-100']                        # ['train-clean-100', 'train-clean-360', 'train-other-500'] for pre-training. ['train-clean-360'] or ['train-clean-100'] for libri phone exp or cpc phone exp, respectively.
  dev_set: ['dev-clean']                                #
  test_set: ['test-clean']                              #
  train_proportion: 1.0                                 # Currently only effect the `phone classification task`, use this percent of `train_set` for downstream task training to demonstrate mockingjay generality


runner:
  learning_rate: '4e-3'                                 # Learning rate for opt: ['4e-3' for fine-tune, '4e-3' for regualr downstream task training]
  warmup_proportion: 0.07                               # Proportion of training to perform linear rate warmup.
  gradient_clipping: 1.0                                # Maximum gradient norm
  total_steps: 500000                                   # total steps for training, a step is a batch of update
  log_step: 2000                                        # log training status every this amount of training steps
  save_step: 2000                                       # save model every this amount of training steps
  dev_step: 10000                                       # evaluate every this amount of training steps
  evaluation: 'dev'                                     # can be 'dev' or 'test', show inference results and saves the best model
  max_keep: 2                                           # maximum number of model ckpt to keep during training


model:                                                  # downstream model config, each task can have different model setting
  
  phone_linear:
    hidden_size: 0                                      # when linear: True, the hidden_size is ignored
    drop: 0.0                                           # The dropout ratio, not used when `linear` is set to `True`.
    linear: True                                        # whether to make the classifier linear
    layers: 1                                           # number of layers in the classifier, set to 2 for 1 hidden layer
    concat: 1                                           # `int`, must be an odd number. Concatenation of this amount of windows to match the average size of a phoneme. Set to 1 for no concatenation, set to 9 to concat 4 previous and 4 future frames.

  phone_1hidden:
    hidden_size: 768                                    # hidden size of classifier
    drop: 0.0                                           # The dropout ratio, not used when `linear` is set to `True`.
    linear: False                                       # whether to make the classifier linear
    layers: 2                                           # number of layers in the classifier, set to 2 for 1 hidden layer
    concat: 1                                           # `int`, must be an odd number. Concatenation of this amount of windows to match the average size of a phoneme. Set to 1 for no concatenation, set to 9 to concat 4 previous and 4 future frames.
  
  phone_concat:
    hidden_size: 0                                      # when linear: True, the hidden_size is ignored
    drop: 0.0                                           # The dropout ratio, not used when `linear` is set to `True`.
    linear: True                                        # whether to make the classifier linear
    layers: 1                                           # number of layers in the classifier, set to 2 for 1 hidden layer
    concat: 9                                           # `int`, must be an odd number. Concatenation of this amount of windows to match the average size of a phoneme. Set to 1 for no concatenation, set to 9 to concat 4 previous and 4 future frames.

  speaker_frame:
    hidden_size: 0                                      # when linear: True, the hidden_size is ignored
    drop: 0.0                                           # The dropout ratio, not used when `linear` is set to `True`.
    linear: True                                        # whether to make the classifier linear
    layers: 1                                           # number of layers in the classifier, set to 2 for 1 hidden layer
    concat: 1                                           # `int`, must be an odd number. Concatenation of this amount of windows to match the average size of a phoneme. Set to 1 for no concatenation, set to 9 to concat 4 previous and 4 future frames.

  speaker_utterance:
    hidden_size: 0                                      # when linear: True, the hidden_size is ignored
    drop: 0.0                                           # The dropout ratio, not used when `linear` is set to `True`.
    linear: True                                        # whether to make the classifier linear
    layers: 1                                           # number of layers in the classifier, set to 2 for 1 hidden layer
    concat: 1                                           # `int`, must be an odd number. Concatenation of this amount of windows to match the average size of a phoneme. Set to 1 for no concatenation, set to 9 to concat 4 previous and 4 future frames.